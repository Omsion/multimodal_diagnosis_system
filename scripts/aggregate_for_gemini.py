#!/usr/bin/env python3
"""
é¡¹ç›®ä»£ç æ±‡é›†è„šæœ¬ - ä¸ºGoogle Gemini APIå‡†å¤‡å®Œæ•´é¡¹ç›®æ–‡æ¡£

è¯¥è„šæœ¬ä¼šé€’å½’éå†æ•´ä¸ªé¡¹ç›®ç›®å½•ï¼Œç”Ÿæˆï¼š
1. å®Œæ•´çš„é¡¹ç›®ç›®å½•æ ‘å½¢ç»“æ„
2. æ‰€æœ‰Pythonæ–‡ä»¶çš„å®Œæ•´ä»£ç å†…å®¹

ç”Ÿæˆçš„æ–‡ä»¶å°†åŒ…å«é¡¹ç›®çš„å®Œæ•´å®ç°ï¼Œä¾¿äºè¾“å…¥ç»™Geminiç­‰å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œåˆ†æã€‚
"""

import os
import sys
from pathlib import Path
from datetime import datetime
from typing import List, Set, Optional
import argparse


class ProjectAggregator:
    """é¡¹ç›®ä»£ç æ±‡é›†å™¨

    è´Ÿè´£æ”¶é›†æ•´ä¸ªé¡¹ç›®çš„ç»“æ„ä¿¡æ¯å’Œä»£ç æ–‡ä»¶ï¼Œç”Ÿæˆå•ä¸€çš„ç»¼åˆæ–‡æ¡£ã€‚
    """

    def __init__(self,
                 root_dir: Optional[Path] = None,
                 output_file: str = "multimodal_dr_diagnosis_for_gemini.txt",
                 include_patterns: Optional[List[str]] = None,
                 exclude_dirs: Optional[List[str]] = None):
        """åˆå§‹åŒ–é¡¹ç›®æ±‡é›†å™¨

        Args:
            root_dir: é¡¹ç›®æ ¹ç›®å½• (å¦‚æœä¸ºNoneï¼Œè‡ªåŠ¨æ£€æµ‹è„šæœ¬æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ä½œä¸ºé¡¹ç›®æ ¹ç›®å½•)
            output_file: è¾“å‡ºæ–‡ä»¶å
            include_patterns: éœ€è¦åŒ…å«çš„æ–‡ä»¶æ¨¡å¼åˆ—è¡¨ (é»˜è®¤: ["*.py"])
            exclude_dirs: éœ€è¦æ’é™¤çš„ç›®å½•åˆ—è¡¨
        """
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ ¹ç›®å½•ï¼Œè‡ªåŠ¨æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•
        if root_dir is None:
            # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
            script_dir = Path(__file__).parent.resolve()
            # å‡è®¾é¡¹ç›®æ ¹ç›®å½•æ˜¯scriptsç›®å½•çš„çˆ¶ç›®å½•
            self.root_dir = script_dir.parent
        else:
            self.root_dir = Path(root_dir).resolve()
        self.output_file = output_file
        self.include_patterns = include_patterns or ["*.py"]
        self.exclude_dirs = set(exclude_dirs or [
            ".git", "__pycache__", ".idea", ".vscode", "node_modules",
            ".pytest_cache", ".coverage", "htmlcov", "dist", "build"
        ])

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_files = 0
        self.total_size = 0
        self.processed_files = []

        print(f"é¡¹ç›®æ ¹ç›®å½•: {self.root_dir}")
        print(f"è¾“å‡ºæ–‡ä»¶: {self.output_file}")

    def is_excluded(self, path: Path) -> bool:
        """æ£€æŸ¥è·¯å¾„æ˜¯å¦åº”è¯¥è¢«æ’é™¤

        Args:
            path: è¦æ£€æŸ¥çš„è·¯å¾„

        Returns:
            bool: Trueè¡¨ç¤ºåº”è¯¥æ’é™¤
        """
        # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤çš„ç›®å½•ä¸­
        for part in path.parts:
            if part in self.exclude_dirs:
                return True
        return False

    def should_include_file(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«åŒ…å«

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            bool: Trueè¡¨ç¤ºåº”è¯¥åŒ…å«
        """
        if self.is_excluded(file_path):
            return False

        # æ’é™¤è„šæœ¬è‡ªèº«
        if file_path.resolve() == Path(__file__).resolve():
            return False

        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        for pattern in self.include_patterns:
            if file_path.match(pattern):
                return True
        return False

    def generate_tree_structure(self, max_depth: int = 3) -> str:
        """ç”Ÿæˆé¡¹ç›®ç›®å½•æ ‘å½¢ç»“æ„

        Args:
            max_depth: æ˜¾ç¤ºçš„æœ€å¤§æ·±åº¦

        Returns:
            str: æ ¼å¼åŒ–çš„æ ‘å½¢ç»“æ„å­—ç¬¦ä¸²
        """
        tree_lines = []
        tree_lines.append("ğŸ“ é¡¹ç›®ç›®å½•ç»“æ„:")
        tree_lines.append("=" * 60)

        def _build_tree(directory: Path, prefix: str = "", depth: int = 0) -> None:
            """é€’å½’æ„å»ºæ ‘å½¢ç»“æ„

            Args:
                directory: å½“å‰ç›®å½•
                prefix: å‰ç¼€å­—ç¬¦ä¸²
                depth: å½“å‰æ·±åº¦
            """
            if depth > max_depth:
                tree_lines.append(f"{prefix}... (æœ€å¤§æ·±åº¦ {max_depth})")
                return

            if self.is_excluded(directory):
                return

            try:
                # è·å–ç›®å½•å†…å®¹å¹¶æ’åº
                items = sorted([item for item in directory.iterdir()
                              if not self.is_excluded(item)],
                             key=lambda x: (x.is_file(), x.name.lower()))

                for i, item in enumerate(items):
                    is_last = i == len(items) - 1
                    current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "

                    if item.is_dir():
                        tree_lines.append(f"{prefix}{current_prefix}ğŸ“ {item.name}/")
                        next_prefix = prefix + ("    " if is_last else "â”‚   ")
                        _build_tree(item, next_prefix, depth + 1)
                    else:
                        # æ˜¾ç¤ºæ–‡ä»¶å›¾æ ‡
                        icon = self._get_file_icon(item)
                        tree_lines.append(f"{prefix}{current_prefix}{icon} {item.name}")

            except PermissionError:
                tree_lines.append(f"{prefix}â””â”€â”€ [æƒé™ä¸è¶³]")

        _build_tree(self.root_dir)
        return "\n".join(tree_lines)

    def _get_file_icon(self, file_path: Path) -> str:
        """è·å–æ–‡ä»¶å¯¹åº”çš„å›¾æ ‡

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            str: æ–‡ä»¶å›¾æ ‡emoji
        """
        suffix = file_path.suffix.lower()
        icon_map = {
            ".py": "ğŸ",
            ".js": "ğŸŸ¨",
            ".ts": "ğŸ”·",
            ".json": "ğŸ“‹",
            ".yaml": "ğŸ“„",
            ".yml": "ğŸ“„",
            ".md": "ğŸ“",
            ".txt": "ğŸ“„",
            ".csv": "ğŸ“Š",
            ".png": "ğŸ–¼ï¸",
            ".jpg": "ğŸ–¼ï¸",
            ".jpeg": "ğŸ–¼ï¸",
            ".gif": "ğŸ–¼ï¸",
            ".pdf": "ğŸ“•",
            ".html": "ğŸŒ",
            ".css": "ğŸ¨",
            ".sql": "ğŸ—ƒï¸",
            ".sh": "ğŸ’»",
            ".bat": "ğŸ’»",
            ".ps1": "ğŸ’»",
        }
        return icon_map.get(suffix, "ğŸ“„")

    def collect_python_files(self) -> List[Path]:
        """æ”¶é›†æ‰€æœ‰Pythonæ–‡ä»¶

        Returns:
            List[Path]: Pythonæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        python_files = []

        print("æœç´¢Pythonæ–‡ä»¶...")
        for root, dirs, files in os.walk(self.root_dir):
            # è¿‡æ»¤æ‰æ’é™¤çš„ç›®å½•
            dirs[:] = [d for d in dirs if not self.is_excluded(Path(root) / d)]

            for file in files:
                file_path = Path(root) / file
                if self.should_include_file(file_path):
                    python_files.append(file_path)

        print(f"æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")
        return sorted(python_files)

    def format_file_content(self, file_path: Path) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å†…å®¹

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            str: æ ¼å¼åŒ–åçš„æ–‡ä»¶å†…å®¹
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            try:
                with open(file_path, 'r', encoding='gbk') as f:
                    content = f.read()
            except UnicodeDecodeError:
                return f"// æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: ç¼–ç é”™è¯¯"
        except Exception as e:
            return f"// è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}"

        # è·å–ç›¸å¯¹è·¯å¾„
        rel_path = file_path.relative_to(self.root_dir)

        # æ„å»ºæ–‡ä»¶å¤´éƒ¨
        header = [
            "=" * 80,
            f"ğŸ“ æ–‡ä»¶è·¯å¾„: {rel_path}",
            f"ğŸ“ æ–‡ä»¶å¤§å°: {len(content)} å­—èŠ‚",
            f"ğŸ•’ æœ€åä¿®æ”¹: {datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')}",
            "=" * 80,
            ""
        ]

        # å¦‚æœæ–‡ä»¶ä¸ºç©ºï¼Œæ·»åŠ æç¤º
        if not content.strip():
            content = "# æ­¤æ–‡ä»¶ä¸ºç©º"

        return "\n".join(header) + content + "\n\n"

    def generate_summary(self, python_files: List[Path]) -> str:
        """ç”Ÿæˆé¡¹ç›®ç»Ÿè®¡æ‘˜è¦

        Args:
            python_files: Pythonæ–‡ä»¶åˆ—è¡¨

        Returns:
            str: æ ¼å¼åŒ–çš„ç»Ÿè®¡æ‘˜è¦
        """
        total_lines = 0
        total_chars = 0
        file_stats = []

        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                lines = len(content.splitlines())
                chars = len(content)
                total_lines += lines
                total_chars += chars
                file_stats.append({
                    'path': file_path.relative_to(self.root_dir),
                    'lines': lines,
                    'chars': chars
                })
            except:
                pass

        summary = [
            "ğŸ“Š é¡¹ç›®ç»Ÿè®¡ä¿¡æ¯:",
            "=" * 60,
            f"ğŸ Pythonæ–‡ä»¶æ€»æ•°: {len(python_files)}",
            f"ğŸ“ æ€»ä»£ç è¡Œæ•°: {total_lines:,}",
            f"ğŸ’¾ æ€»å­—ç¬¦æ•°: {total_chars:,}",
            f"ğŸ“ˆ å¹³å‡æ¯æ–‡ä»¶è¡Œæ•°: {total_lines // len(python_files) if python_files else 0}",
            ""
        ]

        # æ·»åŠ æœ€å¤§çš„10ä¸ªæ–‡ä»¶
        if file_stats:
            summary.append("ğŸ“‹ æœ€å¤§çš„10ä¸ªPythonæ–‡ä»¶:")
            file_stats.sort(key=lambda x: x['lines'], reverse=True)
            for i, stat in enumerate(file_stats[:10], 1):
                summary.append(f"  {i:2d}. {stat['path']} ({stat['lines']} è¡Œ)")

        summary.append("")
        return "\n".join(summary)

    def run(self) -> None:
        """æ‰§è¡Œé¡¹ç›®æ±‡é›†ä»»åŠ¡"""
        print("å¼€å§‹æ±‡é›†é¡¹ç›®ä»£ç ...")
        start_time = datetime.now()

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = self.root_dir / self.output_file
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # æ”¶é›†å†…å®¹
        content_sections = []

        # 1. æ·»åŠ å¤´éƒ¨ä¿¡æ¯å’ŒGeminiå¼•å¯¼è¯­
        header = [
            "#" * 80,
            "# å¤šæ¨¡æ€åŒ»å­¦å½±åƒè¯Šæ–­ç³»ç»Ÿ - å®Œæ•´é¡¹ç›®ä»£ç ",
            "#" * 80,
            f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"# é¡¹ç›®æ ¹ç›®å½•: {self.root_dir}",
            f"# è¾“å‡ºæ–‡ä»¶: {self.output_file}",
            f"# ç›®æ ‡æ¨¡å‹: Google Gemini",
            "#" * 80,
            ""
        ]
        content_sections.append("\n".join(header))

        # æ·»åŠ Geminiå¼•å¯¼è¯­
        gemini_prompt = self._generate_gemini_prompt()
        content_sections.append(gemini_prompt)

        # 2. ç”Ÿæˆé¡¹ç›®ç›®å½•æ ‘
        print("ç”Ÿæˆé¡¹ç›®ç›®å½•ç»“æ„...")
        content_sections.append(self.generate_tree_structure())
        content_sections.append("\n\n")

        # 3. æ”¶é›†å¹¶æ ¼å¼åŒ–æ‰€æœ‰Pythonæ–‡ä»¶
        python_files = self.collect_python_files()
        content_sections.append(self.generate_summary(python_files))

        print("è¯»å–Pythonæ–‡ä»¶å†…å®¹...")
        content_sections.append("\n" + "=" * 80 + "\n")
        content_sections.append("Pythonä»£ç æ–‡ä»¶è¯¦ç»†å†…å®¹:\n")

        for i, file_path in enumerate(python_files, 1):
            print(f"  ({i}/{len(python_files)}) å¤„ç†: {file_path.relative_to(self.root_dir)}")
            content_sections.append(self.format_file_content(file_path))
            self.processed_files.append(file_path)

        # 4. æ·»åŠ ç»“æŸæ ‡è®°
        footer = [
            "=" * 80,
            "# é¡¹ç›®ä»£ç æ±‡é›†å®Œæˆ",
            f"# ç»Ÿè®¡: {len(python_files)} ä¸ªPythonæ–‡ä»¶",
            f"# ç”¨æ—¶: {(datetime.now() - start_time).total_seconds():.2f} ç§’",
            "=" * 80
        ]
        content_sections.append("\n".join(footer))

        # å†™å…¥è¾“å‡ºæ–‡ä»¶
        print(f"å†™å…¥è¾“å‡ºæ–‡ä»¶: {output_path}")
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(content_sections))

        # å®Œæˆä¿¡æ¯
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        print("é¡¹ç›®ä»£ç æ±‡é›†å®Œæˆ!")
        print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"å¤„ç†æ–‡ä»¶æ•°: {len(python_files)}")
        print(f"è¾“å‡ºæ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024 / 1024:.2f} MB")
        print(f"æ€»ç”¨æ—¶: {duration:.2f} ç§’")

    def _generate_gemini_prompt(self) -> str:
        """ç”Ÿæˆé’ˆå¯¹Geminiçš„å¼•å¯¼è¯­

        Returns:
            str: Geminiå¼•å¯¼è¯­
        """
        return """
ğŸ¤– Gemini AI å¼•å¯¼è¯­:

Hello Gemini! I need your expert help with my Python project for a multi-modal medical diagnosis system.

ğŸ“‹ Your Role:
Act as an expert AI engineer and Python developer with deep specialization in:
- Multi-modal systems (vision + language)
- Computer vision and medical image analysis
- Natural language processing and RAG systems
- LangChain and FastAPI framework development
- PyTorch and transformer models

ğŸ¥ Project Context:
The code I'm providing is a complete system for **Multi-Modal Diabetic Retinopathy (DR) Diagnosis**.
It integrates computer vision with Large Language Models to provide intelligent medical diagnosis.

ğŸ—ï¸ System Architecture:
1. **Configuration Management** (`settings.py`): Centralized Pydantic settings for model paths and parameters
2. **Vision Processing** (`vision_processors.py`):
   - ResNet50 model for DR grading and classification
   - Qwen-VL visual language model for generating lesion descriptions
3. **LLM Integration** (`llm_loader.py`): R1-7B model with LoRA fine-tuning, LangChain compatible
4. **RAG Pipeline** (`rag_chain_builder.py`): Advanced retrieval-augmented generation using:
   - FAISS vector store for medical knowledge retrieval
   - LangChain Expression Language (LCEL) for chain construction
   - Chain-of-Thought reasoning prompts
5. **FastAPI Service** (`main.py`): RESTful API with `/diagnose` endpoint for complete workflow
6. **Tools & Utilities** (`utils/`): Helper functions for data processing and system operations

ğŸ¯ Your Task:
1. **Analyze & Understand**: Comprehend the entire codebase, understanding component interactions
2. **Confirm Understanding**: Respond with "I have analyzed the complete multi-modal DR diagnosis system and understand the workflow from visual analysis to RAG-based diagnostic report generation. I am ready to assist. What would you like me to help with?"
3. **Provide Assistance**: Help with debugging, code improvements, architecture suggestions, feature additions, and optimization

ğŸ“ Code Structure:
All Python files are provided below with clear file path delimiters and content formatting.

"""


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="æ±‡é›†é¡¹ç›®ä»£ç åˆ°å•ä¸€æ–‡ä»¶ï¼Œä¾¿äºè¾“å…¥ç»™Geminiç­‰å¤§è¯­è¨€æ¨¡å‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python aggregate_for_gemini.py
  python aggregate_for_gemini.py --output my_project.txt
  python aggregate_for_gemini.py --include "*.py" "*.yaml" "*.md"
        """
    )

    parser.add_argument(
        "--output", "-o",
        default="multimodal_dr_diagnosis_for_gemini.txt",
        help="è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: multimodal_dr_diagnosis_for_gemini.txt)"
    )

    parser.add_argument(
        "--include", "-i",
        nargs="*",
        default=["*.py"],
        help="è¦åŒ…å«çš„æ–‡ä»¶æ¨¡å¼ (é»˜è®¤: ['*.py'])"
    )

    parser.add_argument(
        "--exclude", "-e",
        nargs="*",
        default=[".git", "__pycache__", ".idea", ".vscode", "node_modules"],
        help="è¦æ’é™¤çš„ç›®å½• (é»˜è®¤: ['.git', '__pycache__', '.idea', '.vscode', 'node_modules'])"
    )

    parser.add_argument(
        "--root", "-r",
        default=None,
        help="é¡¹ç›®æ ¹ç›®å½• (é»˜è®¤: è‡ªåŠ¨æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•)"
    )

    parser.add_argument(
        "--depth", "-d",
        type=int,
        default=5,
        help="ç›®å½•æ ‘æ˜¾ç¤ºçš„æœ€å¤§æ·±åº¦ (é»˜è®¤: 5)"
    )

    args = parser.parse_args()

    # æ£€æŸ¥æ ¹ç›®å½•æ˜¯å¦å­˜åœ¨ï¼ˆå¦‚æœæŒ‡å®šäº†çš„è¯ï¼‰
    root_dir = None
    if args.root:
        root_dir = Path(args.root)
        if not root_dir.exists():
            print(f"é”™è¯¯: æ ¹ç›®å½•ä¸å­˜åœ¨: {root_dir}")
            sys.exit(1)

    # åˆ›å»ºå¹¶è¿è¡Œæ±‡é›†å™¨
    aggregator = ProjectAggregator(
        root_dir=root_dir,
        output_file=args.output,
        include_patterns=args.include,
        exclude_dirs=args.exclude
    )

    try:
        aggregator.run()
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"è¿è¡Œæ—¶é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()