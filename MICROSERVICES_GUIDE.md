# ⚠️ 文档已过时

> [!WARNING]
> **本文档描述的微服务架构方案并未实现，请勿参考！**

本文档最初计划将项目重构为微服务架构，以支持在不同Conda环境中运行不同模型。但**实际项目采用了更实用的方案**：

## 当前实际架构

项目采用**单体应用 + API模式**的架构：

- **架构类型**：单体FastAPI应用
- **部署方式**：单个服务，一个命令启动
- **模型部署**：
  - DR分级模型：本地ResNet152
  - 视觉描述：API调用（Qwen-VL-Max）或本地模型
  - 推理LLM：API调用（DeepSeek-Chat）或本地模型

## 如何启动项目？

请参考 **[README.md](README.md)** 获取准确的启动指南。

**简要步骤**：

1. **配置环境**：
   ```bash
   conda activate your_environment
   pip install -r requirements.txt
   ```

2. **配置 `.env` 文件**（从 `.env.example` 复制）

3. **初始化向量数据库**（首次运行）：
   ```bash
   python scripts/init_vector_db.py
   ```

4. **启动服务**：
   ```bash
   python run_service.py
   ```

5. **访问服务**：http://localhost:8000

---

## 为什么没有实现微服务架构？

微服务架构在此场景下存在以下问题：

1. **过度设计**：单用户诊断系统不需要微服务的复杂性
2. **资源浪费**：多个服务进程会消耗更多内存
3. **更好的方案存在**：API模式已经解决了"不同环境运行不同模型"的需求

## API模式的优势

通过配置文件即可切换本地/API模式，无需微服务架构：

- ✅ **灵活性**：一键切换本地模型或API调用
- ✅ **简单性**：单个服务，易于部署和维护
- ✅ **资源效率**：仅在需要时加载模型
- ✅ **成本可控**：硬件不足时使用API，硬件充足时本地运行

---

**📖 完整文档请查阅：[README.md](README.md)**
